import { useState } from "react";
import { Button } from "@/components/ui/button";
import { Card, CardContent } from "@/components/ui/card";
import { Input } from "@/components/ui/input";

export default function SoraNaviMobile() {
  const [image, setImage] = useState(null);
  const [descriptions, setDescriptions] = useState({
    Japanese: "",
    English: "",
    Chinese: "",
    Korean: ""
  });
  const [loading, setLoading] = useState(false);

  const handleImageChange = (e) => {
    const file = e.target.files[0];
    if (file) {
      setImage(file);
      fetchImageDescription(file);
    }
  };

  const fetchImageDescription = async (file) => {
    setLoading(true);

    const reader = new FileReader();
    reader.onloadend = async () => {
      const base64Image = reader.result;

      try {
        const res = await fetch("/api/image-to-desc", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ image: base64Image })
        });

        const data = await res.json();
        const resultText = data.result || "èª¬æ˜ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚";

        const langTexts = {
          Japanese: resultText.match(/æ—¥æœ¬èª[:ï¼š]\s*(.+)/)?.[1] || "ï¼ˆå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰",
          English: resultText.match(/è‹±èª[:ï¼š]\s*(.+)/)?.[1] || "ï¼ˆå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰",
          Chinese: resultText.match(/ä¸­å›½èªï¼ˆç°¡ä½“å­—ï¼‰[:ï¼š]\s*(.+)/)?.[1] || "ï¼ˆå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰",
          Korean: resultText.match(/éŸ“å›½èª[:ï¼š]\s*(.+)/)?.[1] || "ï¼ˆå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰",
        };

        setDescriptions(langTexts);
      } catch (err) {
        console.error(err);
        setDescriptions({
          Japanese: "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
          English: "An error occurred.",
          Chinese: "å‘ç”Ÿé”™è¯¯ã€‚",
          Korean: "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        });
      }

      setLoading(false);
    };

    reader.readAsDataURL(file);
  };

  const playTTS = (text) => {
    const utterance = new SpeechSynthesisUtterance(text);
    speechSynthesis.speak(utterance);
  };

  const languages = [
    { key: "Japanese", label: "æ—¥æœ¬èª" },
    { key: "English", label: "English" },
    { key: "Chinese", label: "ä¸­æ–‡ï¼ˆç®€ä½“å­—ï¼‰" },
    { key: "Korean", label: "í•œêµ­ì–´" }
  ];

  return (
    <div className="p-4 max-w-md mx-auto">
      <h1 className="text-2xl font-bold mb-4 text-center text-sky-600">ğŸ›£ï¸ ç©ºãƒŠãƒ“ãƒ»å¤šè¨€èªã‚¬ã‚¤ãƒ‰</h1>
      <Card className="mb-4 shadow-md">
        <CardContent className="flex flex-col items-center gap-4">
          <Input type="file" accept="image/*" onChange={handleImageChange} className="w-full" />
          {image && (
            <img
              src={URL.createObjectURL(image)}
              alt="é¸æŠã•ã‚ŒãŸç”»åƒ"
              className="rounded-xl w-full object-cover max-h-64 border"
            />
          )}
        </CardContent>
      </Card>
      {loading ? (
        <p className="text-center text-gray-600">è§£æä¸­...</p>
      ) : (
        languages.map((lang) => (
          <Card key={lang.key} className="mb-2 shadow-sm border-l-4 border-sky-400">
            <CardContent className="p-3">
              <div className="flex items-center justify-between">
                <span className="font-semibold text-sky-700">{lang.label}</span>
                <Button variant="ghost" size="sm" onClick={() => playTTS(descriptions[lang.key])}>ğŸ”Š</Button>
              </div>
              <p className="text-sm text-gray-800 mt-1 whitespace-pre-wrap">{descriptions[lang.key]}</p>
            </CardContent>
          </Card>
        ))
      )}
    </div>
  );
}
