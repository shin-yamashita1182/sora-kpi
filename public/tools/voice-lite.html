<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>VoiceLight Viewer</title>
  <style>
    body {
      margin: 0;
      background-color: black;
      color: white;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
    }
    #slide {
      max-width: 100vw;
      max-height: 85vh;
    }
    #mic {
      margin-top: 10px;
      font-size: 24px;
      padding: 10px 20px;
      background-color: #333;
      color: white;
      border: none;
      border-radius: 10px;
    }
    #mic.listening {
      background-color: #2196F3;
    }
  </style>
</head>
<body>
  <img id="slide" src="/tools/slide1.jpg" alt="ã‚¹ãƒ©ã‚¤ãƒ‰1" />
  <button id="mic">ğŸ¤ éŸ³å£°ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«é–‹å§‹</button>

  <script>
    let currentSlide = 1;
    const maxSlides = 5;
    const slideEl = document.getElementById("slide");
    const micBtn = document.getElementById("mic");

    function updateSlide(n) {
      currentSlide = Math.max(1, Math.min(maxSlides, n));
      slideEl.src = `/tools/slide${currentSlide}.jpg`;
      slideEl.alt = `ã‚¹ãƒ©ã‚¤ãƒ‰${currentSlide}`;
    }

    function nextSlide() {
      if (currentSlide < maxSlides) updateSlide(currentSlide + 1);
    }

    function prevSlide() {
      if (currentSlide > 1) updateSlide(currentSlide - 1);
    }

    function startVoiceControl() {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        alert("éŸ³å£°èªè­˜ã«éå¯¾å¿œã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ã™ã€‚");
        return;
      }

      const recognition = new SpeechRecognition();
      recognition.lang = "ja-JP";
      recognition.continuous = true;

      recognition.onstart = () => {
        micBtn.classList.add("listening");
        micBtn.textContent = "ğŸ™ èãå–ã‚Šä¸­â€¦ã€Œæ¬¡ã¸ã€ã€Œæˆ»ã‚‹ã€ãªã©";
      };

      recognition.onresult = (event) => {
        const transcript = event.results[event.results.length - 1][0].transcript.trim();
        console.log("ğŸ§ èªè­˜çµæœ:", transcript);

        if (transcript.includes("æ¬¡") || transcript.includes("ã™ã™ã‚€")) nextSlide();
        else if (transcript.includes("æˆ»") || transcript.includes("ã‚‚ã©ã‚‹")) prevSlide();
        else if (transcript.includes("æœ€åˆ")) updateSlide(1);
        else if (transcript.includes("æœ€å¾Œ")) updateSlide(maxSlides);
      };

      recognition.onerror = (e) => {
        console.error("éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼", e);
      };

      recognition.onend = () => {
        micBtn.classList.remove("listening");
        micBtn.textContent = "ğŸ¤ éŸ³å£°ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«å†é–‹";
      };

      recognition.start();
    }

    micBtn.addEventListener("click", startVoiceControl);
  </script>
</body>
</html>
